{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 源码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_attention_mask_from_input_mask(from_tensor, to_mask):\n",
    "    \"\"\"Create 3D attention mask from a 2D tensor mask.\n",
    "\n",
    "    Args:\n",
    "      from_tensor: 2D or 3D Tensor of shape [batch_size, from_seq_length, ...].\n",
    "      to_mask: int32 Tensor of shape [batch_size, to_seq_length].\n",
    "\n",
    "    Returns:\n",
    "      float Tensor of shape [batch_size, from_seq_length, to_seq_length].\n",
    "    \"\"\"\n",
    "    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n",
    "    batch_size = from_shape[0]\n",
    "    from_seq_length = from_shape[1]\n",
    "\n",
    "    to_shape = get_shape_list(to_mask, expected_rank=2)\n",
    "    to_seq_length = to_shape[1]\n",
    "\n",
    "    to_mask = tf.cast(\n",
    "        tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n",
    "\n",
    "    # We don't assume that `from_tensor` is a mask (although it could be). We\n",
    "    # don't actually care if we attend *from* padding tokens (only *to* padding)\n",
    "    # tokens so we create a tensor of all ones.\n",
    "    #\n",
    "    # `broadcast_ones` = [batch_size, from_seq_length, 1]\n",
    "    broadcast_ones = tf.ones(\n",
    "        shape=[batch_size, from_seq_length, 1], dtype=tf.float32)\n",
    "\n",
    "    # Here we broadcast along two dimensions to create the mask.\n",
    "    mask = broadcast_ones * to_mask\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_tensor = tf.ones([2,4])\n",
    "to_mask = tf.constant([[1,1,1,0],[1,1,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "    batch_size = 2\n",
    "    from_seq_length = 4\n",
    "    to_seq_length = 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 4), dtype=float32, numpy=\n",
       "array([[[1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    to_mask = tf.cast(\n",
    "        tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n",
    "    to_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    broadcast_ones = tf.ones(\n",
    "        shape=[batch_size, from_seq_length, 1], dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 4), dtype=float32, numpy=\n",
       "array([[[1., 1., 1., 0.],\n",
       "        [1., 1., 1., 0.],\n",
       "        [1., 1., 1., 0.],\n",
       "        [1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0.],\n",
       "        [1., 1., 0., 0.],\n",
       "        [1., 1., 0., 0.],\n",
       "        [1., 1., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    # Here we broadcast along two dimensions to create the mask.\n",
    "    mask = broadcast_ones * to_mask\n",
    "    mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
